{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Training DoMINO Model on the Ahmed body surface dataset\n",
    "\n",
    "In this notebook, we will first provide a detailed explanation of the DoMINO architecture, which is a multi-scale, iterative neural operator designed for modeling large-scale engineering simulations. We will break down the key components of DoMINO, including its use of local geometry representations, multi-scale point convolution kernels, and its efficient handling of complex geometries. Afterward, we will train the model using the **Ahmed body surface dataset**, a widely used dataset in automotive aerodynamics simulations. *As indicated in the previous notebook this dataset was created by the NVIDIA Physics NeMo development team and differs from other similar datasets hosted on cloud platforms like AWS.* \n",
    "\n",
    "The DoMINO model is capable of training both volume fields (such as velocity and pressure) and surface fields (including pressure and wall shear stress). However, for the sake of simplicity and educational purposes, this notebook will *focus solely on training the surface fields* using the Ahmed body surface dataset.\n",
    "*\n",
    "\n",
    "## Table of Contents\n",
    "- [DoMINO Architecture](#domino-architecture)\n",
    "  - [Global Geometry Representation](#global-geometry-representation)\n",
    "  - [Local Geometry Representation](#local-geometry-representation)\n",
    "  - [Basis Function Neural Network](#basis-function-neural-network)\n",
    "  - [Concatenating the Latent Vector with the Local Geometry Encoding](#concatenating-the-latent-vector-with-the-local-geometry-encoding)\n",
    "  - [Passing Through Additional Neural Network Layers](#passing-through-additional-neural-network-layers)\n",
    "  - [Aggregation Network](#aggregation-network)\n",
    "- [Training Process](#training)\n",
    "  - [Step 1: Define Experiment Parameters and Dependencies](#step-1-define-experiment-parameters-and-dependencies)\n",
    "    - [Loading Required Libraries](#loading-required-libraries)\n",
    "    - [Dependencies](#dependencies)\n",
    "    - [Experiment Parameters and Variables](#experiment-parameters-and-variables)\n",
    "  - [Step 2: Train the DoMINO Model](#step-2-train-the-domino-model)\n",
    "    - [Understanding the Training Process](#understanding-the-training-process)\n",
    "    - [Key Components and Libraries](#key-components-and-libraries)\n",
    "    - [Important Training Parameters](#important-training-parameters)\n",
    "    - [Implementation Overview](#implementation-overview)\n",
    "- [Load Model Checkpoint & Run Inference](#Load-Model-Checkpoint-&-Run-Inference)\n",
    "- [Visualizing the predicted results](#Visualizing-the-predicted-results)\n",
    "\n",
    "\n",
    "## DoMINO Architecture\n",
    "Machine learning (ML) models have been proposed as surrogate models to speed up simulations, but they face limitations, particularly in terms of accuracy, scalability, and generalization to new geometries.\n",
    "DoMINO, a new ML model designed to address these challenges. DoMINO is a multi-scale, iterative neural operator that uses local geometric information to predict flow fields in large-scale simulations. It is specifically validated for the automotive aerodynamics use case, showcasing its scalability, accuracy, and ability to generalize across different simulation scenarios. Let's walk through the DoMINO architecture step by step, starting from the *Global Geometry Representation, through to the Local Geometry Representation, and then to the Aggregation Network.*\n",
    "\n",
    "The DoMINO model evaluates solution fields within a computational domain by leveraging geometry representations in STL file format. It encodes global geometry information on a fixed-size grid, defined in the computational domain, through a combination of learnable point convolution kernels, CNNs, and dense networks. Local geometric encoding is extracted, using point convolution kernels, from the global encoding by dynamically constructing local subdomains around sampled points where the solution fields are evaluated. This approach enables the prediction of volume and surface solutions by combining local geometry encoding with basis functions computed for sampled points and their neighboring points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Geometry Representation:\n",
    "The Global Geometry Representation refers to the overall shape and structure of the entire object or domain that you are modeling. This representation captures all the geometric details across the entire computational domain.\\\n",
    "Step-by-Step Explanation of Global Geometry Representation:\n",
    "\n",
    "- **Step 1**: Construct Bounding Boxes\n",
    "\t- A tight-fitting surface bounding box is created around the STL (3D geometry) to hold the geometry.\n",
    "    - A computational domain bounding box is also defined, which is larger than the surface bounding box to encompass the whole computational domain.\n",
    "    - Both bounding boxex can be specified in  ```conf.yaml```\n",
    "- **Step 2**: Project STL Vertices onto Structured Grid\n",
    "\t- The geometric features of the point cloud, such as spatial coordinates, are projected onto an N-dimensional structured grid of resolution m×m×m×f, which is overlaid on the surface bounding box using **learnable point convolution kernels**.\n",
    "\t- The learnable point convolution kernels are created using **differentiable ball query layers**. This means that the method:\n",
    "    \t- Uses a \"ball\" (a sphere in 3D space) around each point to query or find its neighbors.\n",
    "    \t- The ball query layer is \"differentiable,\" meaning it can be included in the neural network and updated via backpropagation (i.e., during training, the network can learn how to adjust the kernels to improve performance).\n",
    "    \t- The radius of the ball (radius of influence) defines how far around each point we look for neighboring points to include in the convolution. This defines, in fact, how far the geometry can affect the grid. A range of point convolutional kernel sizes can be learned by specifying several radii. Moreover, different kernels are learned to represent information on the surface bounding box and computational domain bounding box. This enables multi-scale learning of geometry encoding by representing both short- and long-range interactions of the surface and flow fields.  The radii of influence are defined as **list** in the ```conf.yaml``` file:\n",
    "          ```yaml\n",
    "            volume_radii: [0.1, 0.5]\n",
    "            surface_radii: [0.05]\n",
    "          ```\n",
    "\\\n",
    "          These radius are used in the DoMINO model (```physicsnemo/models/domino/model.py```) to compute two **BQWarp** accordingly:\n",
    "          \n",
    "\n",
    "     \n",
    "```python\n",
    "        class GeometryRep(nn.Module):\n",
    "            \"\"\"Geometry representation from STLs block\"\"\"\n",
    "\n",
    "            def __init__(self, input_features, model_parameters=None):\n",
    "                super().__init__()\n",
    "                geometry_rep = model_parameters.geometry_rep\n",
    "\n",
    "                self.bq_warp = nn.ModuleList()\n",
    "                self.geo_processors = nn.ModuleList()\n",
    "                for j, p in enumerate(radii):\n",
    "                    self.bq_warp.append(\n",
    "                        BQWarp(\n",
    "                            input_features=input_features,\n",
    "                            grid_resolution=model_parameters.interp_res,\n",
    "                            radius=radii[j],\n",
    "                        )\n",
    "                    )\n",
    "                    self.geo_processors.append(\n",
    "                        GeoProcessor(\n",
    "                            input_filters=geometry_rep.geo_conv.base_neurons_out,\n",
    "                            model_parameters=geometry_rep.geo_processor,\n",
    "                        )\n",
    "                    )\n",
    "```\n",
    "       \n",
    "        \n",
    "- **Step 3**: Use Multi-Resolution Approach for Detailed and Coarse Features\n",
    "\t- The grid resolution in the bounding box determines the level of detail of the geometry: \n",
    "    \t- Finer resolution captures more detailed features of the geometry.\n",
    "    \t- Coarser resolution captures larger, broader features.\n",
    "\t- A multi-resolution approach is adopted, meaning multiple grids at different resolutions (levels) are maintained to capture both fine and coarse features of the geometry. The number of resolution levels is a parameter that can be adjusted in conf.yaml file as\n",
    "      ```yaml\n",
    "      GRID_RESOLUTION = [128, 64, 48]  # Resolution of the interpolation grid \n",
    "      ```\n",
    "  - Currently, the DoMINO model allows specification of a single resolution but this configuration will be provided in a future release.\n",
    "\n",
    "- **Step 4**: Propagate Geometry Features into the Computational Domain\n",
    "  - The computational domain is much larger than the surface bounding box, so the geometry information needs to be extended.\n",
    "\t- Geometry features are propagated into the computational domain using two methods: \n",
    "    \t- As explained in **step 2** Multi-scale **point convolution kernels** project the **geometry information** onto the computational domain grid.\n",
    "    \t- **Features** from the surface grid of the bounding box (i.e., Gs) are propagated into the computational domain grid (i.e., Gc) using **CNN blocks** that contain convolution, pooling, and unpooling layers.\n",
    "\t- The CNN blocks are iterated for a specified number of steps to refine the geometry representation. Currently, the DoMINO model is configured to run a single iteration. An option to change this will be provided in ```conf.yaml``` in a future release.\n",
    "\n",
    "- **Step 5**: Calculate Signed Distance Function (SDF) and its Gradients\n",
    "\t- Additionally, the Signed Distance Function (SDF) and its gradient components are calculated on the computational domain grid.\n",
    "\t- These SDF and gradient values are added to the learned features, providing additional information about the topology of the geometry (i.e., the geometry's shape, distances to surfaces, etc.).\n",
    "\n",
    "- **Step 6**: Final Global Geometry Representation\n",
    "\t- The final geometry representation of the STL is formed by combining the learned features from the structured grids at different resolutions in both the bounding box and the computational domain.\n",
    "\n",
    "Once the computational domain is created for each resolution, the next step would be local geometry representation. \n",
    "\n",
    "### Local geometry representation\n",
    "The Local Geometry Representation focuses on the geometry in the immediate vicinity of a sampled point p (the points in simulation mesh). The idea is to understand how the geometry behaves around a specific point and its neighbors, which can be important for accurate predictions. While the Global Geometry Representation gives the big picture, the Local Geometry Representation zooms in on a small region of interest around each sampled point. The key difference is that local geometry represents a smaller, more detailed portion of the global geometry, typically focusing on the small-scale features close to a point. For each sampled point p, neighboring points are sampled randomly around them to form a computational stencil of points similar to finite volume and element methods. The local geometry representation is learned by drawing a subregion around the computational stencil of\n",
    "p + 1 points. The size of the subregion are defined as **list** in the ```conf.yaml``` file:\n",
    "\n",
    "  ```yaml\n",
    "    geometry_local.volume_radii: [0.05, 0.1]\n",
    "    geometry_local.surface_radii: [0.05]\n",
    "  ```\n",
    "\n",
    "**How Does the Multi-Resolution Global Geometry Affect the Local Geometry Representation?**\n",
    " - Coarse resolution: At the coarse resolution, you get a broad view of the object. This can give information about the general shape and large-scale features of the geometry (e.g., the overall shape of the object, major boundaries, etc.). When local geometry is extracted from the coarse resolution, the features are relatively less detailed, and it might capture larger, more general features of the object.\n",
    " - Fine resolution: At the fine resolution, you get a detailed view of the geometry, capturing small features such as intricate surface details, small holes, or sharp edges. The local geometry representation derived from the fine resolution will be more detailed and capture smaller variations in the geometry near each sampled point.\n",
    "\n",
    "**Thus, the global multi-resolution geometry allows the local geometry to be learned at different levels of detail, depending on the resolution of the grid that is used to represent the geometry.** \n",
    "\n",
    "### Basis Function Neural Network (Latent Vector):\n",
    "- Once the local geometry representation is built, it is passed through a Basis Function Neural Network.\\\n",
    "  What happens here:    \n",
    "- The input features (coordinates, SDF, normal vectors, etc. and their fourier features) for each point in the stencil are fed into the Basis Function Neural Network. This is a fully connected neural network that processes these features.\n",
    "- The network then computes a latent vector for each point in the stencil. A latent vector is a compressed mathematical representation that encodes the important information about each point’s geometry and position.\n",
    "- Purpose: The latent vector captures the essential characteristics of each point’s geometry in a compact form, which will be used in later steps for predicting the solution at that point.\n",
    "\n",
    "### Concatenating the Latent Vector with the Local Geometry Encoding:\n",
    "- After calculating the latent vector for each point, this vector is concatenated with the local geometry encoding — which includes the previously computed information from the surrounding points and the global geometry.\n",
    "- Why this is done: Concatenating these two representations allows the network to use both the specific local features of each point and the broader context of the surrounding geometry to make predictions.\n",
    "\n",
    "### Passing Through Additional Neural Network Layers (Solution Prediction):\n",
    "- The combined information (latent vector + local geometry encoding) is passed through another set of fully connected layers (a new neural network).\n",
    "- What happens here: These layers process the combined information and predict a solution vector for each point in the stencil. The solution vector could represent various physical quantities such as temperature, pressure, or other simulation results at the sampled point.\n",
    "- Purpose: This step produces the predicted solution at each point, based on the local and global geometry.\n",
    "\n",
    "### Aggregation Network:\n",
    "Aggregation network is a fully connected neural network with a **DeepONet** like structure, **Local geometry rep is branch net and basis functions are trunk net**, which is used to compute solutions.\n",
    "\n",
    "\n",
    "- Local Geometry Representation is the Branch Net: The branch network in DeepONet is responsible for processing the local geometry representation (like the shape or physical location of the point and its neighbors in the domain). In this case, the branch net processes the features around the sampled point (i) and its neighbors (j).\n",
    "- Basis Functions are the Trunk Net: The trunk network in DeepONet processes additional data (like the global features or functions) to help represent the solution space better. Here, the basis functions represent mathematical components that help capture the underlying solution in the computational domain.\n",
    "\n",
    "- Aggregation network computes the solution field on the sampled point, i and its neighbors j. The solutions are then averaged using an inverse distance weighted interpolation scheme.\\\n",
    "In simpler terms:\n",
    "\n",
    "- The aggregation network computes the solution values at the sampled point (i) and its surrounding neighbors (j). The solution is a value that corresponds to a field (e.g., temperature, pressure) at these points.\n",
    "- After computing the solution at the sampled point and its neighbors, the results are combined (averaged) using an inverse distance weighting scheme. This means that points closer to the sampled point (i) contribute more to the final solution than points farther away. The \"inverse distance\" part means that the influence of a neighbor's solution decreases the farther it is from the sampled point. \n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 10px;\">\n",
    "  <figure style=\"text-align: center;\">\n",
    "    <img src=\"img/global_geo_rep.png\" style=\"width: 65%; height: auto;\">\n",
    "    <figcaption>Computation and surface Bounding box representation.</figcaption>\n",
    "  </figure>\n",
    "  <figure style=\"text-align: center;\">\n",
    "    <img src=\"img/aggregation_net.png\" style=\"width: 45%; height: auto;\">\n",
    "    <figcaption>Local geometry encoding and Aggregation network. The Aggregation network is a fully connected neural network with a DeepONet like structure, where Local geometry rep is branch net and basis functions are trunk net.</figcaption>\n",
    "  </figure>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### **Step 1: Define Experiment Parameters and Dependencies**\n",
    "\n",
    "The first step in training the DoMINO model on the Ahmed body dataset is to set up our experiment environment and define the necessary parameters. This includes specifying paths to our data, configuring training settings, and ensuring all required libraries are available.\n",
    "\n",
    "Key components we need to set up:\n",
    "- Data paths for training and validation sets\n",
    "- Model hyperparameters and training configurations\n",
    "- Visualization settings for results\n",
    "- Required Python libraries for mesh processing and deep learning\n",
    "\n",
    "#### Loading Required Libraries\n",
    "\n",
    "Before we proceed with the experiment setup, let's first import all the necessary libraries. These libraries will be used for:\n",
    "- Deep learning and numerical computations (torch, numpy)\n",
    "- Progress tracking and visualization (tqdm, matplotlib)\n",
    "\n",
    "#### Dependencies\n",
    "Ensure that the required Python libraries are installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy torch matplotlib tqdm mlflow torchinfo\n",
    "```\n",
    "\n",
    "Let's start by installing mlflow for experiment tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/warp/codegen.py:2735: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  ast.Str: emit_String,  # Deprecated in 3.8; use Constant\n",
      "/usr/local/lib/python3.12/dist-packages/warp/codegen.py:2736: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  ast.Num: emit_Num,  # Deprecated in 3.8; use Constant\n",
      "/usr/local/lib/python3.12/dist-packages/warp/codegen.py:2737: DeprecationWarning: ast.NameConstant is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  ast.NameConstant: emit_NameConstant,  # Deprecated in 3.8; use Constant\n",
      "/usr/local/lib/python3.12/dist-packages/warp/codegen.py:2754: DeprecationWarning: ast.Ellipsis is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  ast.Ellipsis: emit_Ellipsis,\n",
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "\n",
    "import pyvista as pv\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import apex\n",
    "import numpy as np\n",
    "import hydra\n",
    "from hydra.utils import to_absolute_path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "from physicsnemo.launch.utils import load_checkpoint, save_checkpoint\n",
    "from physicsnemo.utils.sdf import signed_distance_field\n",
    "\n",
    "from physicsnemo.datapipes.cae.domino_datapipe import DoMINODataPipe\n",
    "from physicsnemo.models.domino.model import DoMINO\n",
    "from physicsnemo.utils.domino.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Parameters and Variables\n",
    "\n",
    "In this section, we define all the necessary parameters and variables for our Ahmed body experiment. These parameters control various aspects of the training process, data processing, and model configuration.\n",
    "\n",
    "These parameters are carefully chosen based on:\n",
    "- The physical dimensions of the Ahmed body\n",
    "- The computational requirements of the DoMINO model\n",
    "- The desired resolution for accurate flow prediction\n",
    "- The available computational resources\n",
    "- The specific requirements of the aerodynamic analysis\n",
    "\n",
    "The bounding box parameters are particularly important as they define the computational domain for both volume and surface meshes, ensuring we capture all relevant flow features around the Ahmed body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and Path Configuration\n",
    "EXPERIMENT_TAG = 4  # Unique identifier for this experiment run\n",
    "PROJECT_NAME = \"ahmed_body_dataset\"  # Name of the project\n",
    "OUTPUT_DIR = Path(f\"/workspace/exercises/outputs/{PROJECT_NAME}/{EXPERIMENT_TAG}\")  # Directory for experiment outputs\n",
    "DATA_DIR = Path(\"/workspace/ahmed_body_dataset/\")  # Root directory for dataset\n",
    "PROCESSED_DIR = DATA_DIR / \"prepared_surface_data\"  # Directory for processed surface data\n",
    "CHECKPOINT_DIR = OUTPUT_DIR / \"models\"  # Directory for saving model checkpoints\n",
    "SAVE_PATH = DATA_DIR / \"mesh_predictions_surf_final1\" # path to save prediction results\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Physical Variables\n",
    "VOLUME_VARS = [\"p\"]  # Volume variables to predict (pressure)\n",
    "SURFACE_VARS = [\"p\", \"wallShearStress\"]  # Surface variables to predict\n",
    "MODEL_TYPE = \"surface\"  # Type of model (surface-only prediction)\n",
    "AIR_DENSITY = 1.205  # Air density in kg/m³\n",
    "STREAM_VELOCITY = 60\n",
    "\n",
    "# Training Hyperparameters\n",
    "NUM_EPOCHS = 3  # Number of training epochs\n",
    "LR = 0.001  # Learning rate\n",
    "BATCH_SIZE = 1  # Batch size for training\n",
    "GRID_RESOLUTION = [128, 64, 48]  # Resolution of the interpolation grid\n",
    "NUM_SURFACE_NEIGHBORS = 7  # Number of neighbors for surface operations\n",
    "NORMALIZATION = \"min_max_scaling\"  # Data normalization method\n",
    "INTEGRAL_LOSS_SCALING = 0  # Scaling factor for integral loss\n",
    "NUM_SURF_VARS = 4  # Number of surface variables to predict, 3 for vectore (wallShearStress) and 1 for scalar (p)\n",
    "CHECKPOINT_INTERVAL = 1  # Save checkpoint every N epochs\n",
    "\n",
    "# Dataset Paths\n",
    "DATA_PATHS = {\n",
    "    \"train\": \"/workspace/ahmed_body_dataset/train_prepared_surface_data\",\n",
    "    \"val\": \"/workspace/ahmed_body_dataset/validation_prepared_surface_data\",\n",
    "    \"test\": '/workspace/ahmed_body_dataset/test'\n",
    "}\n",
    "\n",
    "# Model and Scaling Factor Paths\n",
    "MODEL_SAVE_DIR = \"./outputs/ahmed_body_dataset/4/models\"\n",
    "SURF_SAVE_PATH = './outputs/ahmed_body_dataset/surface_scaling_factors.npy'\n",
    "\n",
    "# Bounding Box Configuration for Volume and Surface Meshes\n",
    "BOUNDING_BOX = SimpleNamespace(\n",
    "    max=[0.5, 0.6, 0.6],  # Maximum coordinates for volume mesh\n",
    "    min=[-2.5, -0.5, -0.5] # Minimum coordinates for volume mesh\n",
    ")\n",
    "BOUNDING_BOX_SURF = SimpleNamespace(\n",
    "    max=[0.01, 0.6, 0.4],  # Maximum coordinates for surface mesh\n",
    "    min=[-1.5, -0.01, -0.01] # Minimum coordinates for surface mesh\n",
    ")\n",
    "\n",
    "# Set cuDNN benchmark mode\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_distributed():\n",
    "    \"\"\"\n",
    "    Initialize distributed training environment.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (device, rank, world_size)\n",
    "            - device: torch.device for computation\n",
    "            - rank: process rank in distributed setup\n",
    "            - world_size: total number of processes\n",
    "    \"\"\"\n",
    "    rank = int(os.environ.get('RANK', 0))\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "    \n",
    "    # Set up CUDA device\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    print(\"torch.cuda.set_device(local_rank)\", torch.cuda.set_device(local_rank))\n",
    "    print(\"rank:::\",rank)\n",
    "    print(\"world_size, local_rank\",world_size, local_rank)\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    \n",
    "    # Initialize distributed process group if needed\n",
    "    if world_size > 1:\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    \n",
    "    return device, rank, world_size\n",
    "\n",
    "def mse_loss_fn(output, target, padded_value=-10):\n",
    "    \"\"\"\n",
    "    Compute masked MSE loss, ignoring padded values.\n",
    "    \n",
    "    Args:\n",
    "        output (torch.Tensor): Model predictions\n",
    "        target (torch.Tensor): Ground truth values\n",
    "        padded_value (float): Value used for padding (default: -10)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Mean squared error loss\n",
    "    \"\"\"\n",
    "    # Move target to same device as output\n",
    "    target = target.to(output.device)\n",
    "    # Create mask for non-padded values\n",
    "    mask = torch.abs(target - padded_value) > 1e-3\n",
    "    # Compute masked loss\n",
    "    masked_loss = torch.sum(((output - target) ** 2) * mask) / torch.sum(mask)\n",
    "    return masked_loss.mean()\n",
    "\n",
    "def create_dataset(phase):\n",
    "    \"\"\"\n",
    "    Create DoMINO dataset for specified phase (train/val).\n",
    "    \n",
    "    Args:\n",
    "        phase (str): Dataset phase ('train' or 'val')\n",
    "    \n",
    "    Returns:\n",
    "        DoMINODataPipe: Configured dataset\n",
    "    \"\"\"\n",
    "    return DoMINODataPipe(\n",
    "        DATA_PATHS[phase],\n",
    "        phase=phase,\n",
    "        grid_resolution=GRID_RESOLUTION,\n",
    "        surface_variables=SURFACE_VARS,\n",
    "        normalize_coordinates=True,\n",
    "        sampling=True,\n",
    "        sample_in_bbox=True,\n",
    "        volume_points_sample=8192,\n",
    "        surface_points_sample=4096, ## \n",
    "        geom_points_sample=200000,\n",
    "        positional_encoding=False,\n",
    "        surface_factors=np.load(SURF_SAVE_PATH),\n",
    "        scaling_type=NORMALIZATION,\n",
    "        model_type=MODEL_TYPE,\n",
    "        bounding_box_dims=BOUNDING_BOX,\n",
    "        bounding_box_dims_surf=BOUNDING_BOX_SURF,\n",
    "        num_surface_neighbors=NUM_SURFACE_NEIGHBORS,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloaders(rank, world_size):\n",
    "    \"\"\"\n",
    "    Create train and validation dataloaders with distributed sampling.\n",
    "    \n",
    "    Args:\n",
    "        rank (int): Process rank\n",
    "        world_size (int): Total number of processes\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, train_sampler, val_sampler)\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset, val_dataset = create_dataset(\"train\"), create_dataset(\"val\")\n",
    "    \n",
    "    # Configure distributed samplers if needed\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank) if world_size > 1 else None\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank) if world_size > 1 else None\n",
    "    \n",
    "    # Create dataloaders\n",
    "    return (\n",
    "        DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, shuffle=train_sampler is None),\n",
    "        DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, shuffle=False),\n",
    "        train_sampler, val_sampler\n",
    "    )\n",
    "\n",
    "def create_model(device, rank, world_size):\n",
    "    \"\"\"\n",
    "    Create and configure DoMINO model with distributed training support.\n",
    "    \n",
    "    Args:\n",
    "        device (torch.device): Computation device\n",
    "        rank (int): Process rank\n",
    "        world_size (int): Total number of processes\n",
    "    \n",
    "    Returns:\n",
    "        DoMINO: Configured model (wrapped in DistributedDataParallel if world_size > 1)\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "    # Initialize model with configuration\n",
    "    model = DoMINO(\n",
    "        input_features=3,\n",
    "        output_features_vol=None,\n",
    "        output_features_surf=NUM_SURF_VARS,\n",
    "        model_parameters=SimpleNamespace(\n",
    "            interp_res=GRID_RESOLUTION,\n",
    "            surface_neighbors=NUM_SURFACE_NEIGHBORS,\n",
    "            use_surface_normals=True,\n",
    "            use_only_normals=True,\n",
    "            encode_parameters=True,\n",
    "            positional_encoding=False,\n",
    "            integral_loss_scaling_factor=INTEGRAL_LOSS_SCALING,\n",
    "            normalization=NORMALIZATION,\n",
    "            use_sdf_in_basis_func=True,\n",
    "            geometry_rep=SimpleNamespace(\n",
    "                base_filters=16,\n",
    "                geo_conv=SimpleNamespace(base_neurons=32, base_neurons_out=1, radius_short=0.1, radius_long=0.5, hops=1),\n",
    "                geo_processor=SimpleNamespace(base_filters=8),\n",
    "                geo_processor_sdf=SimpleNamespace(base_filters=8)\n",
    "            ),\n",
    "            nn_basis_functions=SimpleNamespace(base_layer=512),\n",
    "            parameter_model=SimpleNamespace(base_layer=512, scaling_params=[60.0, 1.226]),\n",
    "            position_encoder=SimpleNamespace(base_neurons=512),\n",
    "            geometry_local=SimpleNamespace(neighbors_in_radius=64, radius=0.05, base_layer=512),\n",
    "            aggregation_model=SimpleNamespace(base_layer=512),\n",
    "            model_type=MODEL_TYPE\n",
    "        ),\n",
    "    ).to(device)\n",
    "    \n",
    "    # Wrap model for distributed training if needed\n",
    "    if world_size > 1:\n",
    "        model = DistributedDataParallel(\n",
    "            model, \n",
    "            device_ids=[rank], \n",
    "            output_device=rank, \n",
    "            find_unused_parameters=True\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_epoch(train_loader, val_loader, model, optimizer, scaler, device, epoch, best_vloss, rank, world_size):\n",
    "    \"\"\"\n",
    "    Run one training epoch with validation.\n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader): Training data loader\n",
    "        val_loader (DataLoader): Validation data loader\n",
    "        model (DoMINO): Model to train\n",
    "        optimizer (torch.optim.Optimizer): Optimizer\n",
    "        scaler (GradScaler): Gradient scaler for mixed precision\n",
    "        device (torch.device): Computation device\n",
    "        epoch (int): Current epoch number\n",
    "        best_vloss (float): Best validation loss so far\n",
    "        rank (int): Process rank\n",
    "        world_size (int): Total number of processes\n",
    "    \n",
    "    Returns:\n",
    "        float: Validation loss for this epoch\n",
    "    \"\"\"\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\") if rank == 0 else train_loader\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # Move batch to device\n",
    "        batch = dict_to_device(batch, device)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with autocast():\n",
    "            _, pred_surf = model(batch)\n",
    "            loss = mse_loss_fn(pred_surf, batch[\"surface_fields\"])\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Update loss tracking\n",
    "        train_loss += loss.item()\n",
    "        if rank == 0:\n",
    "            pbar.set_postfix({\n",
    "                \"train_loss\": f\"{train_loss/(pbar.n+1):.5e}\", \n",
    "                \"lr\": f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "            })\n",
    "    \n",
    "    # Compute average training loss\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = sum(\n",
    "            mse_loss_fn(model(dict_to_device(batch, device))[1], batch[\"surface_fields\"].to(device)).item() \n",
    "            for batch in val_loader\n",
    "        ) / len(val_loader)\n",
    "    \n",
    "    # Handle distributed training metrics\n",
    "    if world_size > 1:\n",
    "        avg_train_loss, val_loss = [torch.tensor(v, device=device) for v in [avg_train_loss, val_loss]]\n",
    "        torch.distributed.all_reduce(avg_train_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        torch.distributed.all_reduce(val_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_train_loss, val_loss = avg_train_loss.item() / world_size, val_loss.item() / world_size\n",
    "    \n",
    "    # Save checkpoints on main process\n",
    "    if rank == 0:\n",
    "        if val_loss < best_vloss:\n",
    "            save_checkpoint(\n",
    "                os.path.join(MODEL_SAVE_DIR, \"best_model\"), \n",
    "                models=model,\n",
    "                optimizer=optimizer,\n",
    "                scaler=scaler\n",
    "            )\n",
    "\n",
    "        if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            save_checkpoint(\n",
    "                MODEL_SAVE_DIR, \n",
    "                models=model, \n",
    "                optimizer=optimizer, \n",
    "                scaler=scaler, \n",
    "                epoch=epoch\n",
    "            )\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "def train(model, device, rank, world_size):\n",
    "    \"\"\"\n",
    "    Function that orchestrates the training process.\n",
    "    Handles distributed training setup, model creation and training loop.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create output directory on main process\n",
    "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True) if rank == 0 else None\n",
    "    \n",
    "    # Set up data\n",
    "    train_loader, val_loader, train_sampler, val_sampler = create_dataloaders(rank, world_size)\n",
    "\n",
    "    optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Initialize learning rate scheduler and gradient scaler\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1, 2], gamma=0.5)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Training loop\n",
    "    best_vloss = float('inf')\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        if world_size > 1:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        best_vloss = min(\n",
    "            best_vloss, \n",
    "            run_epoch(\n",
    "                train_loader, val_loader, model, optimizer, \n",
    "                scaler, device, epoch, best_vloss, rank, world_size\n",
    "            )\n",
    "        )\n",
    "        #scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Train the DoMINO Model**\n",
    "\n",
    "The fifth step in our workflow focuses on training the DoMINO (Deep Mesh Operator Network) model on our processed CFD data. This step is crucial because:\n",
    "- It enables the model to learn complex fluid dynamics patterns\n",
    "- Provides a foundation for accurate flow field predictions\n",
    "- Allows for efficient inference on new geometries\n",
    "- Supports distributed training for improved performance\n",
    "\n",
    "#### Understanding the Training Process\n",
    "\n",
    "The training process involves several key components:\n",
    "1. Setting up distributed training environment\n",
    "2. Creating and configuring datasets and dataloaders\n",
    "3. Initializing the DoMINO model architecture\n",
    "4. Implementing training and validation loops\n",
    "5. Managing model checkpoints and metrics\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following for training:\n",
    "\n",
    "- **PyTorch**\n",
    "   - `torch.distributed`: For distributed training\n",
    "   - `torch.cuda`: For GPU acceleration\n",
    "   - `torch.optim`: For optimization algorithms\n",
    "\n",
    "- **Data Management**\n",
    "   - Custom dataset classes for CFD data\n",
    "   - Distributed samplers for efficient data loading\n",
    "   - Distributed samplers for efficient data loading\n",
    "\n",
    "#### Important Training Parameters\n",
    "\n",
    "During the training process, we need to consider:\n",
    "- Batch size and learning rate\n",
    "- Number of epochs and validation frequency\n",
    "- Model architecture parameters\n",
    "- Loss function configuration\n",
    "- Checkpointing strategy\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The training is implemented through several key components:\n",
    "\n",
    "1. **Distributed Setup**\n",
    "```python\n",
    "def setup_distributed():\n",
    "    \"\"\"Initialize distributed training environment.\"\"\"\n",
    "    # Sets up CUDA devices and process groups\n",
    "```\n",
    "\n",
    "2. **Model Creation**\n",
    "```python\n",
    "def create_model(device, rank, world_size):\n",
    "    \"\"\"Create and configure DoMINO model.\"\"\"\n",
    "    # Initializes model with specified parameters\n",
    "```\n",
    "\n",
    "3. **Training Loop**\n",
    "```python\n",
    "def train(model, device, rank, world_size):\n",
    "    \"\"\"Orchestrates the training process.\"\"\"\n",
    "    # Handles training loop, validation, and checkpointing\n",
    "```\n",
    "\n",
    "Let's proceed with implementing these components and training our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the train for few epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.set_device(local_rank) None\n",
      "rank::: 0\n",
      "world_size, local_rank 1 0\n",
      "Warp 1.6.2 initialized:\n",
      "   CUDA Toolkit 12.8, Driver 12.8\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA RTX 6000 Ada Generation\" (47 GiB, sm_89, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /root/.cache/warp/1.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|                                                                      | 0/408 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module physicsnemo.utils.sdf 36297e8 load on device 'cuda:0' took 182.52 ms  (cached)\n",
      "Module physicsnemo.models.layers.ball_query 1a82cc9 load on device 'cuda:0' took 66.98 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|███████████████████████| 408/408 [01:24<00:00,  4.81it/s, train_loss=4.37507e+02, lr=1.00e-03]\n",
      "\u001b[93m`DistributedManager` not initialized already. Initializing now, but this might lead to unexpected errors\u001b[0m\n",
      "/usr/local/lib/python3.12/dist-packages/physicsnemo/distributed/manager.py:403: UserWarning: Could not initialize using ENV, SLURM or OPENMPI methods. Assuming this is a single process job\n",
      "  warn(\n",
      "Epoch 2/3: 100%|███████████████████████| 408/408 [01:24<00:00,  4.85it/s, train_loss=1.25529e+02, lr=1.00e-03]\n",
      "Epoch 3/3: 100%|███████████████████████| 408/408 [01:24<00:00,  4.85it/s, train_loss=8.41205e+01, lr=1.00e-03]\n"
     ]
    }
   ],
   "source": [
    "# Initialize distributed training\n",
    "device, rank, world_size = setup_distributed()\n",
    "# Set up model\n",
    "model = create_model(device, rank, world_size)\n",
    "# Run training\n",
    "train(model, device, rank, world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Model Checkpoint & Run Inference**\n",
    "\n",
    "The sixth step in our workflow focuses on evaluating our trained DoMINO model by loading the best checkpoint and running inference on sample cases. \n",
    "To run the inference, the script needs several key **inputs**. It requires the 3D shape of the object defined in an STL file and a corresponding surface mesh provided as a VTP file, which also contain results from a traditional simulation for comparison purposes. \n",
    "Crucially, it needs the pre-trained DoMINO AI model loaded from a checkpoint file. Additionally, basic flow conditions like air speed (`STREAM_VELOCITY`) and density (`AIR_DENSITY`), along with specific scaling factors saved from the training phase (used to convert model outputs to physical values), must be provided.\n",
    "\n",
    "\n",
    "As its main **output**, the script generates new VTP files for each tested geometry. These files include the original surface mesh data but are augmented with new data fields representing the AI model's predictions for aerodynamic quantities such as surface pressure and wall shear stress. Furthermore, the script calculates aerodynamic forces based on these predictions and prints a comparison against forces derived from reference data directly to the console.\n",
    "The code snippet below takes geometry files (STL) and corresponding simulation setup data (partially from VTP files and config parameters), preprocesses them, feeds them into the model to predict aerodynamic quantities (like surface pressure and shear stress), and saves these predictions back into VTP files for analysis and visualization.\n",
    "\n",
    "#### Understanding the Testing Process\n",
    "\n",
    "The testing process involves several key components:\n",
    "1. Loading the best model checkpoint\n",
    "2. Preparing test data\n",
    "3. Running inference on test cases\n",
    "4. Analyzing prediction results\n",
    "5. Comparing with ground truth values\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following libraries for testing:\n",
    "\n",
    "1. **PyTorch**\n",
    "   - `torch.load()`: For loading model checkpoints\n",
    "   - `model.load_state_dict()`: For restoring model weights\n",
    "   - `torch.no_grad()`: For efficient inference\n",
    "\n",
    "2. **Custom Testing Functions**\n",
    "   - `test_step()`: For running inference on test cases\n",
    "   - Data processing utilities for test data preparation\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The testing is implemented through several key components:\n",
    "\n",
    "1. **Function test_step**\n",
    "    Within the **test_step** function, several key operations execute in sequence. Initially, torch.no_grad() is used to disable gradient tracking in PyTorch, optimizing performance by saving memory and computation time as gradients are unnecessary during inference. \n",
    "Next, the necessary data is prepared by extracting inputs like air density, stream velocity, geometry coordinates, bounding box grid information (surf_grid), and the Signed Distance Field (SDF) from the data_dict; the SDF is particularly important as it helps the model understand the position of points relative to the geometry surface. \n",
    "Following this, a global geometry encoding is generated using model.geo_rep, which takes normalized geometry points, the grid, and the SDF to create a comprehensive representation of the overall shape. \n",
    "Surface-specific data, including mesh points, normals, areas, and neighbor details (found via methods like KDTree during preprocessing), are then extracted. \n",
    "To refine the focus, model.geo_encoding_local_surface extracts relevant local geometric features from the global encoding specifically for the surface points where predictions are needed. \n",
    "Positional awareness is added using model.position_encoder to encode the relative location of surface points. \n",
    "The core prediction then occurs via model.calculate_solution_with_neighbors, combining local geometry, positional encoding, surface point details, neighbor information, and flow conditions to estimate the target surface fields like pressure coefficient or wall shear stress. Since the model output is normalized, a final un-normalization step converts these predictions back into physical units using the provided surf_factors, stream velocity, and air density. The function concludes by returning the predicted surface fields (prediction_surf), as this specific code path concentrates only on surface predictions.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def test_step(model, data_dict, surf_factors, device):\n",
    "    \"\"\"\n",
    "    Executes the core inference logic for a single test case using the trained DoMINO model.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        data_dict: A dictionary containing all necessary input data for this specific test case (geometry, mesh points, flow conditions, etc.), already preprocessed and formatted.\n",
    "        surf_factors: Scaling factors used during training to normalize the target surface data. Needed here to un-normalize the model's predictions back to physical values.\n",
    "        device: The computational device (CPU or GPU) to run the calculations on.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction_vol, prediction_surf) - Model predictions for volume and surface\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "2. **Function: test**\n",
    "```python\n",
    "def test(model, test_dataloader, device):\n",
    "    \"\"\"\n",
    "    Run testing on the model using the provided test dataloader.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        test_dataloader (DataLoader): DataLoader containing test data\n",
    "        device (torch.device): Device to run inference on\n",
    "        \n",
    "    Returns:\n",
    "        list: List of tuples containing (prediction_vol, prediction_surf) for each test case\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "On the other hand, the test function is a higher-level function that organizes and controls the overall testing process. It begins by checking if surface scaling factors have been pre-computed and stored in a .npy file. If the file exists, it loads these factors; if not, it defaults to None. The function then loads a pre-trained model from a checkpoint file (DoMINO.0.....pt) and loads its state into the model. After the model is loaded, it creates a directory for saving predictions if it doesn't already exist. The dirname parameter is used to extract a tag, which helps identify the current test case.\n",
    "\n",
    "Next, the function proceeds to load the necessary input files. It reads an STL file that contains the 3D geometry of the surface and extracts relevant data like vertices, faces, and areas. The bounding box dimensions are calculated, and the surface’s center of mass is computed. Then, it prepares a grid (surf_grid) and calculates the signed distance function (SDF) over this grid using the surface geometry, which helps in understanding the geometry’s proximity to the grid points. The function then reads the VTP file, which holds additional surface-related data such as pressure and shear force values.\n",
    "\n",
    "The surface fields are then prepared by interpolating the surface mesh data and its corresponding attributes. These fields are normalized to fit within the bounding box dimensions. The data dictionary is assembled, containing all the relevant inputs needed for the model’s prediction. This dictionary includes things like normalized surface coordinates, surface areas, and field values such as stream velocity and air density. The dictionary is converted to PyTorch tensors, making it compatible with the model.\n",
    "\n",
    "The test_step function is then called with this prepared data to compute the model's predictions. After the predictions are generated, the function compares the predicted surface forces (pressure and shear stress) with the true values from the surface fields. It calculates the predicted forces and prints out the comparison between the predicted and true values. The predicted surface fields are then converted to VTK format and saved to a file. Finally, the function finishes by returning, completing the testing process. This function provides a complete pipeline for testing a trained model on surface data, generating predictions, and saving them for further analysis.\n",
    "\n",
    "\n",
    "Let's proceed with loading our trained model and running the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, data_dict, surf_factors, device):\n",
    "    \"\"\"\n",
    "    Run a single test step on the model.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        data_dict (dict): Dictionary containing test data\n",
    "        device (torch.device): Device to run inference on\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction_vol, prediction_surf) - Model predictions for volume and surface\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_tloss_vol = 0.0  # Placeholder for average volume loss (not currently used)\n",
    "    avg_tloss_surf = 0.0  # Placeholder for average surface loss (not currently used)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation to save memory and computation during inference\n",
    "        # Move input data to the specified device (CPU or GPU)\n",
    "        data_dict = dict_to_device(data_dict, device)\n",
    "\n",
    "        # Extract non-dimensionalization factors (important for scaling the inputs)\n",
    "        air_density = data_dict[\"air_density\"]\n",
    "        stream_velocity = data_dict[\"stream_velocity\"]\n",
    "        length_scale = data_dict[\"length_scale\"]\n",
    "\n",
    "        # Extract geometry coordinates (nodes of the surface)\n",
    "        geo_centers = data_dict[\"geometry_coordinates\"]\n",
    "\n",
    "        # Extract bounding box grid and signed distance function (SDF) grid for the surface\n",
    "        s_grid = data_dict[\"surf_grid\"]\n",
    "        sdf_surf_grid = data_dict[\"sdf_surf_grid\"]\n",
    "\n",
    "        # Extract scaling factors for surface (used for un-normalization)\n",
    "        surf_max = data_dict[\"surface_min_max\"][:, 1]\n",
    "        surf_min = data_dict[\"surface_min_max\"][:, 0]\n",
    "\n",
    "        # Normalize geometry coordinates to fit within a bounding box [-1, 1]\n",
    "        geo_centers_surf = (\n",
    "            2.0 * (geo_centers - surf_min) / (surf_max - surf_min) - 1\n",
    "        )\n",
    "\n",
    "        # Generate geometric representation of the surface\n",
    "        encoding_g_surf = model.geo_rep(\n",
    "            geo_centers_surf, s_grid, sdf_surf_grid\n",
    "        )\n",
    "\n",
    "        prediction_vol = None  # Volume prediction is not computed in this function\n",
    "\n",
    "        # Extract information about the surface: mesh centers, normals, areas, and neighbors\n",
    "        surface_mesh_centers = data_dict[\"surface_mesh_centers\"]\n",
    "        surface_normals = data_dict[\"surface_normals\"]\n",
    "        surface_areas = data_dict[\"surface_areas\"]\n",
    "\n",
    "        surface_mesh_neighbors = data_dict[\"surface_mesh_neighbors\"]\n",
    "        surface_neighbors_normals = data_dict[\"surface_neighbors_normals\"]\n",
    "        surface_neighbors_areas = data_dict[\"surface_neighbors_areas\"]\n",
    "\n",
    "        surface_areas = torch.unsqueeze(surface_areas, -1)  # Add extra dimension\n",
    "        surface_neighbors_areas = torch.unsqueeze(surface_neighbors_areas, -1)  # Add extra dimension\n",
    "        pos_surface_center_of_mass = data_dict[\"pos_surface_center_of_mass\"]\n",
    "        num_points = surface_mesh_centers.shape[1]  # Number of surface points\n",
    "        \n",
    "        # Extract target surface fields (for comparison later)\n",
    "        target_surf = data_dict[\"surface_fields\"]\n",
    "        prediction_surf = np.zeros_like(target_surf.cpu().numpy())  # Initialize prediction array\n",
    "\n",
    "        start_time = time.time()  # Record the start time for performance measurement\n",
    "\n",
    "        # Generate local geometric encoding for each surface point\n",
    "        geo_encoding_local = model.geo_encoding_local_surface(\n",
    "            0.5 * encoding_g_surf, surface_mesh_centers, s_grid\n",
    "        )\n",
    "\n",
    "        # Position encoding based on the center of mass of the surface\n",
    "        pos_encoding = pos_surface_center_of_mass\n",
    "        pos_encoding = model.position_encoder(pos_encoding, eval_mode=\"surface\")\n",
    "\n",
    "        # Perform the model prediction using neighbors and other surface data\n",
    "        tpredictions = (\n",
    "            model.calculate_solution_with_neighbors(\n",
    "                surface_mesh_centers,\n",
    "                geo_encoding_local,\n",
    "                pos_encoding,\n",
    "                surface_mesh_neighbors,\n",
    "                surface_normals,\n",
    "                surface_neighbors_normals,\n",
    "                surface_areas,\n",
    "                surface_neighbors_areas,\n",
    "                stream_velocity,\n",
    "                air_density,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Convert model predictions to numpy arrays for further processing\n",
    "        prediction_surf = tpredictions.cpu().numpy()\n",
    "\n",
    "        # Unnormalize the surface predictions and scale them using physical quantities\n",
    "        prediction_surf = (\n",
    "            unnormalize(prediction_surf, surf_factors[0], surf_factors[1])\n",
    "            * stream_velocity[0, 0].cpu().numpy() ** 2.0\n",
    "            * air_density[0, 0].cpu().numpy()\n",
    "        )\n",
    "\n",
    "    return prediction_vol, prediction_surf  # Return volume and surface predictions\n",
    "\n",
    "def test(filepath, dirname):\n",
    "    \"\"\"\n",
    "    High-level function to manage the testing pipeline, including data preparation, model loading, and prediction saving.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the test data directory\n",
    "        dirname (str): Directory name for the test case\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define names of surface variables to be predicted\n",
    "    surface_variable_names = SURFACE_VARS\n",
    "    \n",
    "    # Check if surface scaling factors are available\n",
    "    surf_save_path = os.path.join(\n",
    "        \"outputs\", PROJECT_NAME , \"surface_scaling_factors.npy\"\n",
    "    )\n",
    "    if os.path.exists(surf_save_path):\n",
    "        surf_factors = np.load(surf_save_path)  # Load scaling factors if available\n",
    "    else:\n",
    "        surf_factors = None  # If not available, set to None\n",
    "    \n",
    "    # Load the best model checkpoint\n",
    "    best_checkpoint = torch.load(CHECKPOINT_DIR / \"best_model/DoMINO.0.1.pt\")\n",
    "    model.load_state_dict(best_checkpoint)  # Load the model state\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Set the path to save predictions\n",
    "    pred_save_path = SAVE_PATH\n",
    "    create_directory(pred_save_path)  # Create the output directory if it doesn't exist\n",
    "    \n",
    "    # Extract test case identifier from the directory name\n",
    "    tag = int(re.findall(r\"(\\w+?)(\\d+)\", dirname)[0][1])\n",
    "    vtp_path = filepath  # Path to the VTP file with surface data\n",
    "    \n",
    "    # Prepare the path to save predicted results\n",
    "    vtp_pred_save_path = os.path.join(\n",
    "        pred_save_path, f\"boundary_{tag}_predicted.vtp\"\n",
    "    )\n",
    "    \n",
    "    # Load the STL file for the geometry\n",
    "    path_stl = Path(filepath)\n",
    "    test_file_path = os.path.join(DATA_DIR, \"test_stl_files\")\n",
    "    stl_path = path_stl.parent.parent.joinpath(test_file_path, path_stl.stem + \".stl\")\n",
    "    print(\"stl_path::\", stl_path)\n",
    "    print(\"filepath::\", filepath)\n",
    "    \n",
    "    # Read and process the STL file\n",
    "    reader = pv.get_reader(stl_path)\n",
    "    mesh_stl = reader.read()\n",
    "    stl_vertices = mesh_stl.points\n",
    "    stl_faces = np.array(mesh_stl.faces).reshape((-1, 4))[:, 1:]  # Extract triangular faces\n",
    "    mesh_indices_flattened = stl_faces.flatten()\n",
    "    length_scale = np.amax(np.amax(stl_vertices, 0) - np.amin(stl_vertices, 0))  # Compute scale of the geometry\n",
    "    stl_sizes = mesh_stl.compute_cell_sizes(length=False, area=True, volume=False)\n",
    "    stl_sizes = np.array(stl_sizes.cell_data[\"Area\"], dtype=np.float32)\n",
    "    stl_centers = np.array(mesh_stl.cell_centers().points, dtype=np.float32)\n",
    "    \n",
    "    # Calculate the center of mass of the surface\n",
    "    center_of_mass = calculate_center_of_mass(stl_centers, stl_sizes)\n",
    "    \n",
    "    # Extract bounding box dimensions for the surface\n",
    "    bounding_box_dims_surf = []\n",
    "    bounding_box_dims_surf.append(np.asarray(BOUNDING_BOX_SURF.max))\n",
    "    bounding_box_dims_surf.append(np.asarray(BOUNDING_BOX_SURF.min))\n",
    "    s_max = np.float32(bounding_box_dims_surf[0])\n",
    "    s_min = np.float32(bounding_box_dims_surf[1])\n",
    "    \n",
    "    # Create a 3D grid for the surface\n",
    "    nx, ny, nz = GRID_RESOLUTION\n",
    "    surf_grid = create_grid(s_max, s_min, [nx, ny, nz])\n",
    "    surf_grid_reshaped = surf_grid.reshape(nx * ny * nz, 3)\n",
    "    \n",
    "    # Compute the Signed Distance Field (SDF) on the surface grid\n",
    "    sdf_surf_grid = (\n",
    "        signed_distance_field(\n",
    "            stl_vertices,\n",
    "            mesh_indices_flattened,\n",
    "            surf_grid_reshaped,\n",
    "            use_sign_winding_number=True,\n",
    "        )\n",
    "        .numpy()\n",
    "        .reshape(nx, ny, nz)\n",
    "    )\n",
    "    surf_grid = np.float32(surf_grid)\n",
    "    sdf_surf_grid = np.float32(sdf_surf_grid)\n",
    "    surf_grid_max_min = np.float32(np.asarray([s_min, s_max]))\n",
    "    \n",
    "    # Read the VTP file containing surface data\n",
    "    reader = vtk.vtkXMLPolyDataReader()\n",
    "    reader.SetFileName(vtp_path)\n",
    "    reader.Update()\n",
    "    polydata_surf = reader.GetOutput()\n",
    "    celldata_all = get_node_to_elem(polydata_surf)\n",
    "    celldata = celldata_all.GetCellData()\n",
    "    surface_fields = get_fields(celldata, surface_variable_names)\n",
    "    surface_fields = np.concatenate(surface_fields, axis=-1)\n",
    "    mesh = pv.PolyData(polydata_surf)\n",
    "    \n",
    "    # Extract surface mesh coordinates, neighbors, and normals\n",
    "    surface_coordinates = np.array(mesh.cell_centers().points, dtype=np.float32)\n",
    "    interp_func = KDTree(surface_coordinates)\n",
    "    dd, ii = interp_func.query(surface_coordinates, k=NUM_SURFACE_NEIGHBORS)\n",
    "    surface_neighbors = surface_coordinates[ii]\n",
    "    surface_neighbors = surface_neighbors[:, 1:]\n",
    "    surface_normals = np.array(mesh.cell_normals, dtype=np.float32)\n",
    "    surface_sizes = mesh.compute_cell_sizes(length=False, area=True, volume=False)\n",
    "    surface_sizes = np.array(surface_sizes.cell_data[\"Area\"], dtype=np.float32)\n",
    "    \n",
    "    # Normalize the surface normals and neighbors\n",
    "    surface_normals = (\n",
    "        surface_normals / np.linalg.norm(surface_normals, axis=1)[:, np.newaxis]\n",
    "    )\n",
    "    surface_neighbors_normals = surface_normals[ii]\n",
    "    surface_neighbors_normals = surface_neighbors_normals[:, 1:]\n",
    "    surface_neighbors_sizes = surface_sizes[ii]\n",
    "    surface_neighbors_sizes = surface_neighbors_sizes[:, 1:]\n",
    "    \n",
    "    # Calculate the grid resolution and normalize the surface data\n",
    "    dx, dy, dz = (\n",
    "        (s_max[0] - s_min[0]) / nx,\n",
    "        (s_max[1] - s_min[1]) / ny,\n",
    "        (s_max[2] - s_min[2]) / nz,\n",
    "    )\n",
    "    pos_surface_center_of_mass = surface_coordinates - center_of_mass\n",
    "    surface_coordinates = normalize(surface_coordinates, s_max, s_min)\n",
    "    surface_neighbors = normalize(surface_neighbors, s_max, s_min)\n",
    "    surf_grid = normalize(surf_grid, s_max, s_min)\n",
    "    \n",
    "    # Prepare the data dictionary for model input\n",
    "    geom_centers = np.float32(stl_vertices)\n",
    "    data_dict = {\n",
    "        \"pos_surface_center_of_mass\": np.float32(pos_surface_center_of_mass),\n",
    "        \"geometry_coordinates\": np.float32(geom_centers),\n",
    "        \"surf_grid\": np.float32(surf_grid),\n",
    "        \"sdf_surf_grid\": np.float32(sdf_surf_grid),\n",
    "        \"surface_mesh_centers\": np.float32(surface_coordinates),\n",
    "        \"surface_mesh_neighbors\": np.float32(surface_neighbors),\n",
    "        \"surface_normals\": np.float32(surface_normals),\n",
    "        \"surface_neighbors_normals\": np.float32(surface_neighbors_normals),\n",
    "        \"surface_areas\": np.float32(surface_sizes),\n",
    "        \"surface_neighbors_areas\": np.float32(surface_neighbors_sizes),\n",
    "        \"surface_fields\": np.float32(surface_fields),\n",
    "        \"surface_min_max\": np.float32(surf_grid_max_min),\n",
    "        \"length_scale\": np.array(length_scale, dtype=np.float32),\n",
    "        \"stream_velocity\": np.expand_dims(\n",
    "            np.array(STREAM_VELOCITY, dtype=np.float32), axis=-1\n",
    "        ),\n",
    "        \"air_density\": np.expand_dims(\n",
    "            np.array(AIR_DENSITY, dtype=np.float32), axis=-1\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    # Convert data dictionary to PyTorch tensors\n",
    "    data_dict = {\n",
    "        key: torch.from_numpy(np.expand_dims(np.float32(value), 0))\n",
    "        for key, value in data_dict.items()\n",
    "    }\n",
    "    \n",
    "    # Perform a test step to get the predictions\n",
    "    prediction_vol, prediction_surf = test_step(\n",
    "        model, data_dict, surf_factors, device\n",
    "    )\n",
    "    \n",
    "    # Process the predicted and true surface values to compute forces\n",
    "    surface_sizes = np.expand_dims(surface_sizes, -1)\n",
    "    pres_x_pred = np.sum(\n",
    "        prediction_surf[0, :, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "    )\n",
    "    shear_x_pred = np.sum(prediction_surf[0, :, 1] * surface_sizes[:, 0])\n",
    "    pres_x_true = np.sum(\n",
    "        surface_fields[:, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "    )\n",
    "    shear_x_true = np.sum(surface_fields[:, 1] * surface_sizes[:, 0])\n",
    "    force_x_pred = np.sum(\n",
    "        prediction_surf[0, :, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "        - prediction_surf[0, :, 1] * surface_sizes[:, 0]\n",
    "    )\n",
    "    force_x_true = np.sum(\n",
    "        surface_fields[:, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "        - surface_fields[:, 1] * surface_sizes[:, 0]\n",
    "    )\n",
    "    \n",
    "    # Print the computed forces for comparison\n",
    "    print(dirname, force_x_pred, force_x_true)\n",
    "    \n",
    "    # Convert predictions to VTK format and save the results\n",
    "    surfParam_vtk = numpy_support.numpy_to_vtk(prediction_surf[0, :, 0:1])\n",
    "    surfParam_vtk.SetName(f\"{surface_variable_names[0]}Pred\")\n",
    "    celldata_all.GetCellData().AddArray(surfParam_vtk)\n",
    "    surfParam_vtk = numpy_support.numpy_to_vtk(prediction_surf[0, :, 1:])\n",
    "    surfParam_vtk.SetName(f\"{surface_variable_names[1]}Pred\")\n",
    "    celldata_all.GetCellData().AddArray(surfParam_vtk)\n",
    "    write_to_vtp(celldata_all, vtp_pred_save_path)  # Save to VTP file\n",
    "    \n",
    "    return  # End of the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file case352.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case352.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case352.vtp\n",
      "case352.vtp 388.15958 6.172671\n",
      "Processing file case119.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case119.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case119.vtp\n",
      "case119.vtp 282.1332 7.375049\n",
      "Processing file case635.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case635.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case635.vtp\n",
      "case635.vtp 369.51053 14.087371\n",
      "Processing file case364.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case364.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case364.vtp\n",
      "case364.vtp 401.1226 4.6474195\n",
      "Processing file case751.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case751.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case751.vtp\n",
      "case751.vtp 413.2344 24.74669\n",
      "Processing file case776.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case776.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case776.vtp\n",
      "case776.vtp 503.37598 8.256935\n",
      "Processing file case49.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case49.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case49.vtp\n",
      "case49.vtp 443.70517 20.909815\n",
      "Processing file case115.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case115.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case115.vtp\n",
      "case115.vtp 402.9986 3.7702813\n",
      "Processing file case726.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case726.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case726.vtp\n",
      "case726.vtp 545.18365 4.6796684\n",
      "Processing file case41.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case41.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case41.vtp\n",
      "case41.vtp 377.52515 11.731827\n",
      "Processing file case161.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case161.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case161.vtp\n",
      "case161.vtp 343.37595 5.284503\n",
      "Processing file case140.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case140.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case140.vtp\n",
      "case140.vtp 432.82495 9.593215\n",
      "Processing file case103.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case103.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case103.vtp\n",
      "case103.vtp 422.27106 7.9935236\n",
      "Processing file case100.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case100.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case100.vtp\n",
      "case100.vtp 418.00107 13.842173\n",
      "Processing file case499.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case499.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case499.vtp\n",
      "case499.vtp 425.19788 7.54636\n",
      "Processing file case178.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case178.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case178.vtp\n",
      "case178.vtp 459.90454 10.5100765\n",
      "Processing file case772.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case772.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case772.vtp\n",
      "case772.vtp 377.3716 27.54496\n",
      "Processing file case802.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case802.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case802.vtp\n",
      "case802.vtp 406.70172 4.3736954\n",
      "Processing file case973.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case973.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case973.vtp\n",
      "case973.vtp 376.6349 18.989792\n",
      "Processing file case819.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case819.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case819.vtp\n",
      "case819.vtp 331.2657 3.844633\n",
      "Processing file case799.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case799.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case799.vtp\n",
      "case799.vtp 384.69418 20.592525\n",
      "Processing file case921.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case921.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case921.vtp\n",
      "case921.vtp 417.12622 14.046066\n",
      "Processing file case598.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case598.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case598.vtp\n",
      "case598.vtp 378.64597 6.979197\n",
      "Processing file case189.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case189.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case189.vtp\n",
      "case189.vtp 306.097 8.8159485\n",
      "Processing file case117.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case117.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case117.vtp\n",
      "case117.vtp 356.59415 13.3055\n",
      "Processing file case548.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case548.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case548.vtp\n",
      "case548.vtp 478.90225 5.363667\n",
      "Processing file case536.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case536.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case536.vtp\n",
      "case536.vtp 348.97147 11.899042\n",
      "Processing file case285.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case285.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case285.vtp\n",
      "case285.vtp 305.52365 4.722199\n",
      "Processing file case671.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case671.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case671.vtp\n",
      "case671.vtp 343.2866 33.31865\n",
      "Processing file case725.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case725.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case725.vtp\n",
      "case725.vtp 544.5346 30.447601\n",
      "Processing file case573.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case573.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case573.vtp\n",
      "case573.vtp 368.84225 16.623365\n",
      "Processing file case652.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case652.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case652.vtp\n",
      "case652.vtp 430.90506 7.546785\n",
      "Processing file case83.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case83.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case83.vtp\n",
      "case83.vtp 379.86826 4.1464777\n",
      "Processing file case901.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case901.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case901.vtp\n",
      "case901.vtp 326.60385 12.164129\n",
      "Processing file case80.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case80.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case80.vtp\n",
      "case80.vtp 354.81894 29.228657\n",
      "Processing file case856.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case856.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case856.vtp\n",
      "case856.vtp 410.29636 9.21023\n",
      "Processing file case165.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case165.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case165.vtp\n",
      "case165.vtp 385.19705 23.197655\n",
      "Processing file case874.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case874.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case874.vtp\n",
      "case874.vtp 444.77805 15.182544\n",
      "Processing file case759.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case759.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case759.vtp\n",
      "case759.vtp 383.89374 22.704792\n",
      "Processing file case30.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case30.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case30.vtp\n",
      "case30.vtp 460.51663 14.250149\n",
      "Processing file case801.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case801.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case801.vtp\n",
      "case801.vtp 381.2007 29.829052\n",
      "Processing file case281.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case281.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case281.vtp\n",
      "case281.vtp 460.25076 6.3821263\n",
      "Processing file case690.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case690.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case690.vtp\n",
      "case690.vtp 486.97684 9.518515\n",
      "Processing file case118.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case118.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case118.vtp\n",
      "case118.vtp 387.4601 24.011112\n",
      "Processing file case911.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case911.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case911.vtp\n",
      "case911.vtp 339.44064 4.34404\n",
      "Processing file case490.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case490.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case490.vtp\n",
      "case490.vtp 407.9492 11.519007\n",
      "Processing file case59.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case59.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case59.vtp\n",
      "case59.vtp 470.31512 33.154274\n",
      "Processing file case526.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case526.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case526.vtp\n",
      "case526.vtp 414.55295 29.625698\n",
      "Processing file case992.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case992.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case992.vtp\n",
      "case992.vtp 421.5604 3.9217348\n",
      "Processing file case55.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case55.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case55.vtp\n",
      "case55.vtp 319.1274 5.553624\n",
      "Predcited results are saved in:  [PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_119_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_49_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_80_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_103_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_725_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_178_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_165_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_115_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_635_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_726_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_874_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_118_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_901_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_856_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_83_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_776_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_671_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_161_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_819_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_690_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_364_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_117_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_352_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_499_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_772_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_30_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_55_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_759_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_598_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_921_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_911_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_59_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_140_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_281_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_801_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_573_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_548_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_973_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_992_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_652_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_490_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_536_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_751_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_285_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_100_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_41_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_799_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_189_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_526_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_802_predicted.vtp')]\n"
     ]
    }
   ],
   "source": [
    "input_path = DATA_PATHS[\"test\"]\n",
    "dirnames = get_filenames(input_path)\n",
    "\n",
    "for count, dirname in enumerate(dirnames):\n",
    "    print(f\"Processing file {dirname}\")\n",
    "    filepath = os.path.join(input_path, dirname)\n",
    "    test(filepath, dirname)\n",
    "\n",
    "folder = Path(SAVE_PATH)\n",
    "predcited_files = list(folder.glob(\"*.vtp\"))\n",
    "print(\"Predcited results are saved in: \",predcited_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizing the predicted results**\n",
    "You can Visualize the predicted surface pressure using either PyVista or ParaView. In the following, use  we `pyvista` and display both the predicted and ground truth pressure values, which are stored in .vtp files located in the SAVE_PATH directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File (/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pv\u001b[38;5;241m.\u001b[39mstart_xvfb()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the VTP mesh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mpv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable cell data keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mesh\u001b[38;5;241m.\u001b[39mcell_data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a Plotter with 2 vertical subplots\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyvista/core/utilities/fileio.py:175\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, force_ext, file_format, progress_bar)\u001b[0m\n\u001b[1;32m    173\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mis_file() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Read file using meshio.read if file_format is present\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_format:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File (/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp) not found"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "# Start virtual framebuffer for off-screen rendering (useful in Jupyter/containers)\n",
    "pv.start_xvfb()\n",
    "\n",
    "# Read the VTP mesh\n",
    "mesh = pv.read(\"/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp\")\n",
    "print(\"Available cell data keys:\", mesh.cell_data.keys())\n",
    "\n",
    "# Create a Plotter with 2 vertical subplots\n",
    "plotter = pv.Plotter(shape=(2, 1), window_size=[1600, 800], off_screen=True)\n",
    "\n",
    "# Plot 'p' (ground truth or reference)\n",
    "plotter.subplot(0, 0)\n",
    "plotter.add_text(\"Pressure (p)\", font_size=12)\n",
    "plotter.add_mesh(mesh, scalars=\"p\", show_edges=False)\n",
    "\n",
    "# Plot 'pPred' (predicted pressure)\n",
    "plotter.subplot(1, 0)\n",
    "plotter.add_text(\"Predicted Pressure (pPred)\", font_size=12)\n",
    "plotter.add_mesh(mesh, scalars=\"pPred\", show_edges=False)\n",
    "\n",
    "# Show both subplots\n",
    "plotter.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
