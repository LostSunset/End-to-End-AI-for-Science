{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3 - Testing DoMINO Model on the Ahmed body surface dataset\n",
    "\n",
    "In this notebook, we will first provide a detailed explanation of the DoMINO architecture, which is a multi-scale, iterative neural operator designed for modeling large-scale engineering simulations. We will break down the key components of DoMINO, including its use of local geometry representations, multi-scale point convolution kernels, and its efficient handling of complex geometries. Afterward, we will train the model using the **Ahmed body surface dataset**, a widely used dataset in automotive aerodynamics simulations. *As indicated in the previous notebook this dataset was created by the NVIDIA Physics NeMo development team and differs from other similar datasets hosted on cloud platforms like AWS.* \n",
    "\n",
    "The DoMINO model is capable of training both volume fields (such as velocity and pressure) and surface fields (including pressure and wall shear stress). However, for the sake of simplicity and educational purposes, this notebook will *focus solely on training the surface fields* using the Ahmed body surface dataset.\n",
    "*\n",
    "\n",
    "## Table of Contents\n",
    "- [Load Model Checkpoint & Run Inference](#Load-Model-Checkpoint-&-Run-Inference)\n",
    "- [Visualizing the predicted results](#Visualizing-the-predicted-results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Model Checkpoint & Run Inference**\n",
    "\n",
    "The sixth step in our workflow focuses on evaluating our trained DoMINO model by loading the best checkpoint and running inference on sample cases. \n",
    "To run the inference, the script needs several key **inputs**. It requires the 3D shape of the object defined in an STL file and a corresponding surface mesh provided as a VTP file, which also contain results from a traditional simulation for comparison purposes. \n",
    "Crucially, it needs the pre-trained DoMINO AI model loaded from a checkpoint file. Additionally, basic flow conditions like air speed (`STREAM_VELOCITY`) and density (`AIR_DENSITY`), along with specific scaling factors saved from the training phase (used to convert model outputs to physical values), must be provided.\n",
    "\n",
    "\n",
    "As its main **output**, the script generates new VTP files for each tested geometry. These files include the original surface mesh data but are augmented with new data fields representing the AI model's predictions for aerodynamic quantities such as surface pressure and wall shear stress. Furthermore, the script calculates aerodynamic forces based on these predictions and prints a comparison against forces derived from reference data directly to the console.\n",
    "The code snippet below takes geometry files (STL) and corresponding simulation setup data (partially from VTP files and config parameters), preprocesses them, feeds them into the model to predict aerodynamic quantities (like surface pressure and shear stress), and saves these predictions back into VTP files for analysis and visualization.\n",
    "\n",
    "#### Understanding the Testing Process\n",
    "\n",
    "The testing process involves several key components:\n",
    "1. Loading the best model checkpoint\n",
    "2. Preparing test data\n",
    "3. Running inference on test cases\n",
    "4. Analyzing prediction results\n",
    "5. Comparing with ground truth values\n",
    "\n",
    "#### Key Components and Libraries\n",
    "\n",
    "We'll use the following libraries for testing:\n",
    "\n",
    "1. **PyTorch**\n",
    "   - `torch.load()`: For loading model checkpoints\n",
    "   - `model.load_state_dict()`: For restoring model weights\n",
    "   - `torch.no_grad()`: For efficient inference\n",
    "\n",
    "2. **Custom Testing Functions**\n",
    "   - `test_step()`: For running inference on test cases\n",
    "   - Data processing utilities for test data preparation\n",
    "\n",
    "#### Implementation Overview\n",
    "\n",
    "The testing is implemented through several key components:\n",
    "\n",
    "1. **Function test_step**\n",
    "    Within the **test_step** function, several key operations execute in sequence. Initially, torch.no_grad() is used to disable gradient tracking in PyTorch, optimizing performance by saving memory and computation time as gradients are unnecessary during inference. \n",
    "Next, the necessary data is prepared by extracting inputs like air density, stream velocity, geometry coordinates, bounding box grid information (surf_grid), and the Signed Distance Field (SDF) from the data_dict; the SDF is particularly important as it helps the model understand the position of points relative to the geometry surface. \n",
    "Following this, a global geometry encoding is generated using model.geo_rep, which takes normalized geometry points, the grid, and the SDF to create a comprehensive representation of the overall shape. \n",
    "Surface-specific data, including mesh points, normals, areas, and neighbor details (found via methods like KDTree during preprocessing), are then extracted. \n",
    "To refine the focus, model.geo_encoding_local_surface extracts relevant local geometric features from the global encoding specifically for the surface points where predictions are needed. \n",
    "Positional awareness is added using model.position_encoder to encode the relative location of surface points. \n",
    "The core prediction then occurs via model.calculate_solution_with_neighbors, combining local geometry, positional encoding, surface point details, neighbor information, and flow conditions to estimate the target surface fields like pressure coefficient or wall shear stress. Since the model output is normalized, a final un-normalization step converts these predictions back into physical units using the provided surf_factors, stream velocity, and air density. The function concludes by returning the predicted surface fields (prediction_surf), as this specific code path concentrates only on surface predictions.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def test_step(model, data_dict, surf_factors, device):\n",
    "    \"\"\"\n",
    "    Executes the core inference logic for a single test case using the trained DoMINO model.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        data_dict: A dictionary containing all necessary input data for this specific test case (geometry, mesh points, flow conditions, etc.), already preprocessed and formatted.\n",
    "        surf_factors: Scaling factors used during training to normalize the target surface data. Needed here to un-normalize the model's predictions back to physical values.\n",
    "        device: The computational device (CPU or GPU) to run the calculations on.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction_vol, prediction_surf) - Model predictions for volume and surface\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "2. **Function: test**\n",
    "```python\n",
    "def test(model, test_dataloader, device):\n",
    "    \"\"\"\n",
    "    Run testing on the model using the provided test dataloader.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        test_dataloader (DataLoader): DataLoader containing test data\n",
    "        device (torch.device): Device to run inference on\n",
    "        \n",
    "    Returns:\n",
    "        list: List of tuples containing (prediction_vol, prediction_surf) for each test case\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "On the other hand, the test function is a higher-level function that organizes and controls the overall testing process. It begins by checking if surface scaling factors have been pre-computed and stored in a .npy file. If the file exists, it loads these factors; if not, it defaults to None. The function then loads a pre-trained model from a checkpoint file (DoMINO.0.....pt) and loads its state into the model. After the model is loaded, it creates a directory for saving predictions if it doesn't already exist. The dirname parameter is used to extract a tag, which helps identify the current test case.\n",
    "\n",
    "Next, the function proceeds to load the necessary input files. It reads an STL file that contains the 3D geometry of the surface and extracts relevant data like vertices, faces, and areas. The bounding box dimensions are calculated, and the surface’s center of mass is computed. Then, it prepares a grid (surf_grid) and calculates the signed distance function (SDF) over this grid using the surface geometry, which helps in understanding the geometry’s proximity to the grid points. The function then reads the VTP file, which holds additional surface-related data such as pressure and shear force values.\n",
    "\n",
    "The surface fields are then prepared by interpolating the surface mesh data and its corresponding attributes. These fields are normalized to fit within the bounding box dimensions. The data dictionary is assembled, containing all the relevant inputs needed for the model’s prediction. This dictionary includes things like normalized surface coordinates, surface areas, and field values such as stream velocity and air density. The dictionary is converted to PyTorch tensors, making it compatible with the model.\n",
    "\n",
    "The test_step function is then called with this prepared data to compute the model's predictions. After the predictions are generated, the function compares the predicted surface forces (pressure and shear stress) with the true values from the surface fields. It calculates the predicted forces and prints out the comparison between the predicted and true values. The predicted surface fields are then converted to VTK format and saved to a file. Finally, the function finishes by returning, completing the testing process. This function provides a complete pipeline for testing a trained model on surface data, generating predictions, and saving them for further analysis.\n",
    "\n",
    "\n",
    "Let's proceed with loading our trained model and running the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, data_dict, surf_factors, device):\n",
    "    \"\"\"\n",
    "    Run a single test step on the model.\n",
    "    \n",
    "    Args:\n",
    "        model (DoMINO): The trained model\n",
    "        data_dict (dict): Dictionary containing test data\n",
    "        device (torch.device): Device to run inference on\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction_vol, prediction_surf) - Model predictions for volume and surface\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_tloss_vol = 0.0  # Placeholder for average volume loss (not currently used)\n",
    "    avg_tloss_surf = 0.0  # Placeholder for average surface loss (not currently used)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation to save memory and computation during inference\n",
    "        # Move input data to the specified device (CPU or GPU)\n",
    "        data_dict = dict_to_device(data_dict, device)\n",
    "\n",
    "        # Extract non-dimensionalization factors (important for scaling the inputs)\n",
    "        air_density = data_dict[\"air_density\"]\n",
    "        stream_velocity = data_dict[\"stream_velocity\"]\n",
    "        length_scale = data_dict[\"length_scale\"]\n",
    "\n",
    "        # Extract geometry coordinates (nodes of the surface)\n",
    "        geo_centers = data_dict[\"geometry_coordinates\"]\n",
    "\n",
    "        # Extract bounding box grid and signed distance function (SDF) grid for the surface\n",
    "        s_grid = data_dict[\"surf_grid\"]\n",
    "        sdf_surf_grid = data_dict[\"sdf_surf_grid\"]\n",
    "\n",
    "        # Extract scaling factors for surface (used for un-normalization)\n",
    "        surf_max = data_dict[\"surface_min_max\"][:, 1]\n",
    "        surf_min = data_dict[\"surface_min_max\"][:, 0]\n",
    "\n",
    "        # Normalize geometry coordinates to fit within a bounding box [-1, 1]\n",
    "        geo_centers_surf = (\n",
    "            2.0 * (geo_centers - surf_min) / (surf_max - surf_min) - 1\n",
    "        )\n",
    "\n",
    "        # Generate geometric representation of the surface\n",
    "        encoding_g_surf = model.geo_rep(\n",
    "            geo_centers_surf, s_grid, sdf_surf_grid\n",
    "        )\n",
    "\n",
    "        prediction_vol = None  # Volume prediction is not computed in this function\n",
    "\n",
    "        # Extract information about the surface: mesh centers, normals, areas, and neighbors\n",
    "        surface_mesh_centers = data_dict[\"surface_mesh_centers\"]\n",
    "        surface_normals = data_dict[\"surface_normals\"]\n",
    "        surface_areas = data_dict[\"surface_areas\"]\n",
    "\n",
    "        surface_mesh_neighbors = data_dict[\"surface_mesh_neighbors\"]\n",
    "        surface_neighbors_normals = data_dict[\"surface_neighbors_normals\"]\n",
    "        surface_neighbors_areas = data_dict[\"surface_neighbors_areas\"]\n",
    "\n",
    "        surface_areas = torch.unsqueeze(surface_areas, -1)  # Add extra dimension\n",
    "        surface_neighbors_areas = torch.unsqueeze(surface_neighbors_areas, -1)  # Add extra dimension\n",
    "        pos_surface_center_of_mass = data_dict[\"pos_surface_center_of_mass\"]\n",
    "        num_points = surface_mesh_centers.shape[1]  # Number of surface points\n",
    "        \n",
    "        # Extract target surface fields (for comparison later)\n",
    "        target_surf = data_dict[\"surface_fields\"]\n",
    "        prediction_surf = np.zeros_like(target_surf.cpu().numpy())  # Initialize prediction array\n",
    "\n",
    "        start_time = time.time()  # Record the start time for performance measurement\n",
    "\n",
    "        # Generate local geometric encoding for each surface point\n",
    "        geo_encoding_local = model.geo_encoding_local_surface(\n",
    "            0.5 * encoding_g_surf, surface_mesh_centers, s_grid\n",
    "        )\n",
    "\n",
    "        # Position encoding based on the center of mass of the surface\n",
    "        pos_encoding = pos_surface_center_of_mass\n",
    "        pos_encoding = model.position_encoder(pos_encoding, eval_mode=\"surface\")\n",
    "\n",
    "        # Perform the model prediction using neighbors and other surface data\n",
    "        tpredictions = (\n",
    "            model.calculate_solution_with_neighbors(\n",
    "                surface_mesh_centers,\n",
    "                geo_encoding_local,\n",
    "                pos_encoding,\n",
    "                surface_mesh_neighbors,\n",
    "                surface_normals,\n",
    "                surface_neighbors_normals,\n",
    "                surface_areas,\n",
    "                surface_neighbors_areas,\n",
    "                stream_velocity,\n",
    "                air_density,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Convert model predictions to numpy arrays for further processing\n",
    "        prediction_surf = tpredictions.cpu().numpy()\n",
    "\n",
    "        # Unnormalize the surface predictions and scale them using physical quantities\n",
    "        prediction_surf = (\n",
    "            unnormalize(prediction_surf, surf_factors[0], surf_factors[1])\n",
    "            * stream_velocity[0, 0].cpu().numpy() ** 2.0\n",
    "            * air_density[0, 0].cpu().numpy()\n",
    "        )\n",
    "\n",
    "    return prediction_vol, prediction_surf  # Return volume and surface predictions\n",
    "\n",
    "def test(filepath, dirname):\n",
    "    \"\"\"\n",
    "    High-level function to manage the testing pipeline, including data preparation, model loading, and prediction saving.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the test data directory\n",
    "        dirname (str): Directory name for the test case\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define names of surface variables to be predicted\n",
    "    surface_variable_names = SURFACE_VARS\n",
    "    \n",
    "    # Check if surface scaling factors are available\n",
    "    surf_save_path = os.path.join(\n",
    "        \"outputs\", PROJECT_NAME , \"surface_scaling_factors.npy\"\n",
    "    )\n",
    "    if os.path.exists(surf_save_path):\n",
    "        surf_factors = np.load(surf_save_path)  # Load scaling factors if available\n",
    "    else:\n",
    "        surf_factors = None  # If not available, set to None\n",
    "    \n",
    "    # Load the best model checkpoint\n",
    "    best_checkpoint = torch.load(CHECKPOINT_DIR / \"best_model/DoMINO.0.1.pt\")\n",
    "    model.load_state_dict(best_checkpoint)  # Load the model state\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Set the path to save predictions\n",
    "    pred_save_path = SAVE_PATH\n",
    "    create_directory(pred_save_path)  # Create the output directory if it doesn't exist\n",
    "    \n",
    "    # Extract test case identifier from the directory name\n",
    "    tag = int(re.findall(r\"(\\w+?)(\\d+)\", dirname)[0][1])\n",
    "    vtp_path = filepath  # Path to the VTP file with surface data\n",
    "    \n",
    "    # Prepare the path to save predicted results\n",
    "    vtp_pred_save_path = os.path.join(\n",
    "        pred_save_path, f\"boundary_{tag}_predicted.vtp\"\n",
    "    )\n",
    "    \n",
    "    # Load the STL file for the geometry\n",
    "    path_stl = Path(filepath)\n",
    "    test_file_path = os.path.join(DATA_DIR, \"test_stl_files\")\n",
    "    stl_path = path_stl.parent.parent.joinpath(test_file_path, path_stl.stem + \".stl\")\n",
    "    print(\"stl_path::\", stl_path)\n",
    "    print(\"filepath::\", filepath)\n",
    "    \n",
    "    # Read and process the STL file\n",
    "    reader = pv.get_reader(stl_path)\n",
    "    mesh_stl = reader.read()\n",
    "    stl_vertices = mesh_stl.points\n",
    "    stl_faces = np.array(mesh_stl.faces).reshape((-1, 4))[:, 1:]  # Extract triangular faces\n",
    "    mesh_indices_flattened = stl_faces.flatten()\n",
    "    length_scale = np.amax(np.amax(stl_vertices, 0) - np.amin(stl_vertices, 0))  # Compute scale of the geometry\n",
    "    stl_sizes = mesh_stl.compute_cell_sizes(length=False, area=True, volume=False)\n",
    "    stl_sizes = np.array(stl_sizes.cell_data[\"Area\"], dtype=np.float32)\n",
    "    stl_centers = np.array(mesh_stl.cell_centers().points, dtype=np.float32)\n",
    "    \n",
    "    # Calculate the center of mass of the surface\n",
    "    center_of_mass = calculate_center_of_mass(stl_centers, stl_sizes)\n",
    "    \n",
    "    # Extract bounding box dimensions for the surface\n",
    "    bounding_box_dims_surf = []\n",
    "    bounding_box_dims_surf.append(np.asarray(BOUNDING_BOX_SURF.max))\n",
    "    bounding_box_dims_surf.append(np.asarray(BOUNDING_BOX_SURF.min))\n",
    "    s_max = np.float32(bounding_box_dims_surf[0])\n",
    "    s_min = np.float32(bounding_box_dims_surf[1])\n",
    "    \n",
    "    # Create a 3D grid for the surface\n",
    "    nx, ny, nz = GRID_RESOLUTION\n",
    "    surf_grid = create_grid(s_max, s_min, [nx, ny, nz])\n",
    "    surf_grid_reshaped = surf_grid.reshape(nx * ny * nz, 3)\n",
    "    \n",
    "    # Compute the Signed Distance Field (SDF) on the surface grid\n",
    "    sdf_surf_grid = (\n",
    "        signed_distance_field(\n",
    "            stl_vertices,\n",
    "            mesh_indices_flattened,\n",
    "            surf_grid_reshaped,\n",
    "            use_sign_winding_number=True,\n",
    "        )\n",
    "        .numpy()\n",
    "        .reshape(nx, ny, nz)\n",
    "    )\n",
    "    surf_grid = np.float32(surf_grid)\n",
    "    sdf_surf_grid = np.float32(sdf_surf_grid)\n",
    "    surf_grid_max_min = np.float32(np.asarray([s_min, s_max]))\n",
    "    \n",
    "    # Read the VTP file containing surface data\n",
    "    reader = vtk.vtkXMLPolyDataReader()\n",
    "    reader.SetFileName(vtp_path)\n",
    "    reader.Update()\n",
    "    polydata_surf = reader.GetOutput()\n",
    "    celldata_all = get_node_to_elem(polydata_surf)\n",
    "    celldata = celldata_all.GetCellData()\n",
    "    surface_fields = get_fields(celldata, surface_variable_names)\n",
    "    surface_fields = np.concatenate(surface_fields, axis=-1)\n",
    "    mesh = pv.PolyData(polydata_surf)\n",
    "    \n",
    "    # Extract surface mesh coordinates, neighbors, and normals\n",
    "    surface_coordinates = np.array(mesh.cell_centers().points, dtype=np.float32)\n",
    "    interp_func = KDTree(surface_coordinates)\n",
    "    dd, ii = interp_func.query(surface_coordinates, k=NUM_SURFACE_NEIGHBORS)\n",
    "    surface_neighbors = surface_coordinates[ii]\n",
    "    surface_neighbors = surface_neighbors[:, 1:]\n",
    "    surface_normals = np.array(mesh.cell_normals, dtype=np.float32)\n",
    "    surface_sizes = mesh.compute_cell_sizes(length=False, area=True, volume=False)\n",
    "    surface_sizes = np.array(surface_sizes.cell_data[\"Area\"], dtype=np.float32)\n",
    "    \n",
    "    # Normalize the surface normals and neighbors\n",
    "    surface_normals = (\n",
    "        surface_normals / np.linalg.norm(surface_normals, axis=1)[:, np.newaxis]\n",
    "    )\n",
    "    surface_neighbors_normals = surface_normals[ii]\n",
    "    surface_neighbors_normals = surface_neighbors_normals[:, 1:]\n",
    "    surface_neighbors_sizes = surface_sizes[ii]\n",
    "    surface_neighbors_sizes = surface_neighbors_sizes[:, 1:]\n",
    "    \n",
    "    # Calculate the grid resolution and normalize the surface data\n",
    "    dx, dy, dz = (\n",
    "        (s_max[0] - s_min[0]) / nx,\n",
    "        (s_max[1] - s_min[1]) / ny,\n",
    "        (s_max[2] - s_min[2]) / nz,\n",
    "    )\n",
    "    pos_surface_center_of_mass = surface_coordinates - center_of_mass\n",
    "    surface_coordinates = normalize(surface_coordinates, s_max, s_min)\n",
    "    surface_neighbors = normalize(surface_neighbors, s_max, s_min)\n",
    "    surf_grid = normalize(surf_grid, s_max, s_min)\n",
    "    \n",
    "    # Prepare the data dictionary for model input\n",
    "    geom_centers = np.float32(stl_vertices)\n",
    "    data_dict = {\n",
    "        \"pos_surface_center_of_mass\": np.float32(pos_surface_center_of_mass),\n",
    "        \"geometry_coordinates\": np.float32(geom_centers),\n",
    "        \"surf_grid\": np.float32(surf_grid),\n",
    "        \"sdf_surf_grid\": np.float32(sdf_surf_grid),\n",
    "        \"surface_mesh_centers\": np.float32(surface_coordinates),\n",
    "        \"surface_mesh_neighbors\": np.float32(surface_neighbors),\n",
    "        \"surface_normals\": np.float32(surface_normals),\n",
    "        \"surface_neighbors_normals\": np.float32(surface_neighbors_normals),\n",
    "        \"surface_areas\": np.float32(surface_sizes),\n",
    "        \"surface_neighbors_areas\": np.float32(surface_neighbors_sizes),\n",
    "        \"surface_fields\": np.float32(surface_fields),\n",
    "        \"surface_min_max\": np.float32(surf_grid_max_min),\n",
    "        \"length_scale\": np.array(length_scale, dtype=np.float32),\n",
    "        \"stream_velocity\": np.expand_dims(\n",
    "            np.array(STREAM_VELOCITY, dtype=np.float32), axis=-1\n",
    "        ),\n",
    "        \"air_density\": np.expand_dims(\n",
    "            np.array(AIR_DENSITY, dtype=np.float32), axis=-1\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    # Convert data dictionary to PyTorch tensors\n",
    "    data_dict = {\n",
    "        key: torch.from_numpy(np.expand_dims(np.float32(value), 0))\n",
    "        for key, value in data_dict.items()\n",
    "    }\n",
    "    \n",
    "    # Perform a test step to get the predictions\n",
    "    prediction_vol, prediction_surf = test_step(\n",
    "        model, data_dict, surf_factors, device\n",
    "    )\n",
    "    \n",
    "    # Process the predicted and true surface values to compute forces\n",
    "    surface_sizes = np.expand_dims(surface_sizes, -1)\n",
    "    pres_x_pred = np.sum(\n",
    "        prediction_surf[0, :, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "    )\n",
    "    shear_x_pred = np.sum(prediction_surf[0, :, 1] * surface_sizes[:, 0])\n",
    "    pres_x_true = np.sum(\n",
    "        surface_fields[:, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "    )\n",
    "    shear_x_true = np.sum(surface_fields[:, 1] * surface_sizes[:, 0])\n",
    "    force_x_pred = np.sum(\n",
    "        prediction_surf[0, :, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "        - prediction_surf[0, :, 1] * surface_sizes[:, 0]\n",
    "    )\n",
    "    force_x_true = np.sum(\n",
    "        surface_fields[:, 0] * surface_normals[:, 0] * surface_sizes[:, 0]\n",
    "        - surface_fields[:, 1] * surface_sizes[:, 0]\n",
    "    )\n",
    "    \n",
    "    # Print the computed forces for comparison\n",
    "    print(dirname, force_x_pred, force_x_true)\n",
    "    \n",
    "    # Convert predictions to VTK format and save the results\n",
    "    surfParam_vtk = numpy_support.numpy_to_vtk(prediction_surf[0, :, 0:1])\n",
    "    surfParam_vtk.SetName(f\"{surface_variable_names[0]}Pred\")\n",
    "    celldata_all.GetCellData().AddArray(surfParam_vtk)\n",
    "    surfParam_vtk = numpy_support.numpy_to_vtk(prediction_surf[0, :, 1:])\n",
    "    surfParam_vtk.SetName(f\"{surface_variable_names[1]}Pred\")\n",
    "    celldata_all.GetCellData().AddArray(surfParam_vtk)\n",
    "    write_to_vtp(celldata_all, vtp_pred_save_path)  # Save to VTP file\n",
    "    \n",
    "    return  # End of the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file case352.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case352.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case352.vtp\n",
      "case352.vtp 388.15958 6.172671\n",
      "Processing file case119.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case119.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case119.vtp\n",
      "case119.vtp 282.1332 7.375049\n",
      "Processing file case635.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case635.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case635.vtp\n",
      "case635.vtp 369.51053 14.087371\n",
      "Processing file case364.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case364.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case364.vtp\n",
      "case364.vtp 401.1226 4.6474195\n",
      "Processing file case751.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case751.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case751.vtp\n",
      "case751.vtp 413.2344 24.74669\n",
      "Processing file case776.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case776.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case776.vtp\n",
      "case776.vtp 503.37598 8.256935\n",
      "Processing file case49.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case49.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case49.vtp\n",
      "case49.vtp 443.70517 20.909815\n",
      "Processing file case115.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case115.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case115.vtp\n",
      "case115.vtp 402.9986 3.7702813\n",
      "Processing file case726.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case726.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case726.vtp\n",
      "case726.vtp 545.18365 4.6796684\n",
      "Processing file case41.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case41.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case41.vtp\n",
      "case41.vtp 377.52515 11.731827\n",
      "Processing file case161.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case161.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case161.vtp\n",
      "case161.vtp 343.37595 5.284503\n",
      "Processing file case140.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case140.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case140.vtp\n",
      "case140.vtp 432.82495 9.593215\n",
      "Processing file case103.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case103.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case103.vtp\n",
      "case103.vtp 422.27106 7.9935236\n",
      "Processing file case100.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case100.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case100.vtp\n",
      "case100.vtp 418.00107 13.842173\n",
      "Processing file case499.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case499.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case499.vtp\n",
      "case499.vtp 425.19788 7.54636\n",
      "Processing file case178.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case178.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case178.vtp\n",
      "case178.vtp 459.90454 10.5100765\n",
      "Processing file case772.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case772.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case772.vtp\n",
      "case772.vtp 377.3716 27.54496\n",
      "Processing file case802.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case802.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case802.vtp\n",
      "case802.vtp 406.70172 4.3736954\n",
      "Processing file case973.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case973.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case973.vtp\n",
      "case973.vtp 376.6349 18.989792\n",
      "Processing file case819.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case819.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case819.vtp\n",
      "case819.vtp 331.2657 3.844633\n",
      "Processing file case799.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case799.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case799.vtp\n",
      "case799.vtp 384.69418 20.592525\n",
      "Processing file case921.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case921.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case921.vtp\n",
      "case921.vtp 417.12622 14.046066\n",
      "Processing file case598.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case598.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case598.vtp\n",
      "case598.vtp 378.64597 6.979197\n",
      "Processing file case189.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case189.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case189.vtp\n",
      "case189.vtp 306.097 8.8159485\n",
      "Processing file case117.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case117.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case117.vtp\n",
      "case117.vtp 356.59415 13.3055\n",
      "Processing file case548.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case548.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case548.vtp\n",
      "case548.vtp 478.90225 5.363667\n",
      "Processing file case536.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case536.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case536.vtp\n",
      "case536.vtp 348.97147 11.899042\n",
      "Processing file case285.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case285.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case285.vtp\n",
      "case285.vtp 305.52365 4.722199\n",
      "Processing file case671.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case671.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case671.vtp\n",
      "case671.vtp 343.2866 33.31865\n",
      "Processing file case725.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case725.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case725.vtp\n",
      "case725.vtp 544.5346 30.447601\n",
      "Processing file case573.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case573.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case573.vtp\n",
      "case573.vtp 368.84225 16.623365\n",
      "Processing file case652.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case652.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case652.vtp\n",
      "case652.vtp 430.90506 7.546785\n",
      "Processing file case83.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case83.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case83.vtp\n",
      "case83.vtp 379.86826 4.1464777\n",
      "Processing file case901.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case901.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case901.vtp\n",
      "case901.vtp 326.60385 12.164129\n",
      "Processing file case80.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case80.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case80.vtp\n",
      "case80.vtp 354.81894 29.228657\n",
      "Processing file case856.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case856.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case856.vtp\n",
      "case856.vtp 410.29636 9.21023\n",
      "Processing file case165.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case165.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case165.vtp\n",
      "case165.vtp 385.19705 23.197655\n",
      "Processing file case874.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case874.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case874.vtp\n",
      "case874.vtp 444.77805 15.182544\n",
      "Processing file case759.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case759.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case759.vtp\n",
      "case759.vtp 383.89374 22.704792\n",
      "Processing file case30.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case30.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case30.vtp\n",
      "case30.vtp 460.51663 14.250149\n",
      "Processing file case801.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case801.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case801.vtp\n",
      "case801.vtp 381.2007 29.829052\n",
      "Processing file case281.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case281.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case281.vtp\n",
      "case281.vtp 460.25076 6.3821263\n",
      "Processing file case690.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case690.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case690.vtp\n",
      "case690.vtp 486.97684 9.518515\n",
      "Processing file case118.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case118.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case118.vtp\n",
      "case118.vtp 387.4601 24.011112\n",
      "Processing file case911.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case911.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case911.vtp\n",
      "case911.vtp 339.44064 4.34404\n",
      "Processing file case490.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case490.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case490.vtp\n",
      "case490.vtp 407.9492 11.519007\n",
      "Processing file case59.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case59.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case59.vtp\n",
      "case59.vtp 470.31512 33.154274\n",
      "Processing file case526.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case526.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case526.vtp\n",
      "case526.vtp 414.55295 29.625698\n",
      "Processing file case992.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case992.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case992.vtp\n",
      "case992.vtp 421.5604 3.9217348\n",
      "Processing file case55.vtp\n",
      "Model loaded\n",
      "stl_path:: /workspace/ahmed_body_dataset/test_stl_files/case55.stl\n",
      "filepath:: /workspace/ahmed_body_dataset/test/case55.vtp\n",
      "case55.vtp 319.1274 5.553624\n",
      "Predcited results are saved in:  [PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_119_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_49_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_80_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_103_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_725_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_178_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_165_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_115_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_635_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_726_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_874_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_118_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_901_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_856_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_83_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_776_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_671_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_161_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_819_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_690_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_364_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_117_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_352_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_499_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_772_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_30_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_55_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_759_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_598_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_921_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_911_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_59_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_140_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_281_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_801_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_573_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_548_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_973_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_992_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_652_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_490_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_536_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_751_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_285_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_100_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_41_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_799_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_189_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_526_predicted.vtp'), PosixPath('/workspace/ahmed_body_dataset/mesh_predictions_surf_final1/boundary_802_predicted.vtp')]\n"
     ]
    }
   ],
   "source": [
    "input_path = DATA_PATHS[\"test\"]\n",
    "dirnames = get_filenames(input_path)\n",
    "\n",
    "for count, dirname in enumerate(dirnames):\n",
    "    print(f\"Processing file {dirname}\")\n",
    "    filepath = os.path.join(input_path, dirname)\n",
    "    test(filepath, dirname)\n",
    "\n",
    "folder = Path(SAVE_PATH)\n",
    "predcited_files = list(folder.glob(\"*.vtp\"))\n",
    "print(\"Predcited results are saved in: \",predcited_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizing the predicted results**\n",
    "You can Visualize the predicted surface pressure using either PyVista or ParaView. In the following, use  we `pyvista` and display both the predicted and ground truth pressure values, which are stored in .vtp files located in the SAVE_PATH directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File (/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pv\u001b[38;5;241m.\u001b[39mstart_xvfb()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the VTP mesh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mpv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable cell data keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mesh\u001b[38;5;241m.\u001b[39mcell_data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a Plotter with 2 vertical subplots\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyvista/core/utilities/fileio.py:175\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, force_ext, file_format, progress_bar)\u001b[0m\n\u001b[1;32m    173\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mis_file() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Read file using meshio.read if file_format is present\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_format:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File (/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp) not found"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "# Start virtual framebuffer for off-screen rendering (useful in Jupyter/containers)\n",
    "pv.start_xvfb()\n",
    "\n",
    "# Read the VTP mesh\n",
    "mesh = pv.read(\"/workspace/data/ahmed_body/mesh_predictions_surf_final1/boundary_417_predicted.vtp\")\n",
    "print(\"Available cell data keys:\", mesh.cell_data.keys())\n",
    "\n",
    "# Create a Plotter with 2 vertical subplots\n",
    "plotter = pv.Plotter(shape=(2, 1), window_size=[1600, 800], off_screen=True)\n",
    "\n",
    "# Plot 'p' (ground truth or reference)\n",
    "plotter.subplot(0, 0)\n",
    "plotter.add_text(\"Pressure (p)\", font_size=12)\n",
    "plotter.add_mesh(mesh, scalars=\"p\", show_edges=False)\n",
    "\n",
    "# Plot 'pPred' (predicted pressure)\n",
    "plotter.subplot(1, 0)\n",
    "plotter.add_text(\"Predicted Pressure (pPred)\", font_size=12)\n",
    "plotter.add_mesh(mesh, scalars=\"pPred\", show_edges=False)\n",
    "\n",
    "# Show both subplots\n",
    "plotter.show(jupyter_backend='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
